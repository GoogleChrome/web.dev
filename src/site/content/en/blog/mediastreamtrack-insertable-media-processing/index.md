---
layout: post
title: Insertable streams for MediaStreamTrack
subhead: |
  The contents of MediaStreamTrack objects exposed as a collection of streams so they can be manipulated
  to introduce new components.
authors:
  - thomassteiner
date: 2021-04-26
description: |
  Insertable streams for MediaStreamTrack expose the contents of a MediaStreamTrack as a collection
  of streams (as defined by the WHATWG Streams API), which can be manipulated to introduce new
  components.
hero: image/8WbTDNrhLsU0El80frMBGE4eMCD3/Qu2wfQ3pxR8AeEfty88S.jpg
alt: Cup of coffee and a laptop with a video conference running showing many participants.
tags:
  - blog # blog is a required tag for the article to show up in the blog.
  - media
  - capabilities
---

{% Aside %} Insertable streams for `MediaStreamTrack` is part of the
[capabilities project](https://web.dev/fugu-status/) and is currently in development. This post will
be updated as the implementation progresses. {% endAside %}

## Background

The
[Media Capture and Streams API](https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API),
often called the Media Streams API or MediaStream API, is an API related to
[WebRTC](https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API) which provides support for
streaming audio and video data.

The API is based on the manipulation of a
[`MediaStream`](https://developer.mozilla.org/en-US/docs/Web/API/MediaStream) object representing a
flux of audio- or video-related data. `MediaStream` objects have a single input and a single output.
A `MediaStream` object generated by
[`getUserMedia()`](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia) is
called local, and has as its source input one of the user's cameras or microphones. A non-local
`MediaStream` may be representing to a media element, like `<video>` or `<audio>`, a stream
originating over the network, and obtained via the WebRTC
[`RTCPeerConnection`](https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection) API, or a
stream created using the Web Audio API
[`MediaStreamAudioSourceNode`](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamAudioSourceNode).

A `MediaStream` consists of zero or more
[`MediaStreamTrack`](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack) objects,
representing various audio or video tracks. Each `MediaStreamTrack` may have one or more channels.
The channel represents the smallest unit of a media stream, such as an audio signal associated with
a given speaker, like left or right in a stereo audio track.

## What is insertable streams for `MediaStreamTrack`?

The core idea for insertable streams for `MediaStreamTrack` is to expose the content of a
`MediaStreamTrack` as a collection of [streams](/streams/) (as defined by the WHATWG
[Streams API](https://streams.spec.whatwg.org/)), which can be manipulated to introduce new
components.

## Use cases

Use cases for insertable streams for `MediaStreamTrack` include, but are not limited to:

- Video conferencing gadgets like "funny hats" or virtual backgrounds.
- Voice processing like software [vocoders](https://en.wikipedia.org/wiki/Vocoder).

## Current status {: #status }

<div class="w-table-wrapper">

| Step                                     | Status                   |
| ---------------------------------------- | ------------------------ |
| 1. Create explainer                      | [Complete][explainer]    |
| 2. Create initial draft of specification | [In Progress][spec]      |
| 3. Gather feedback & iterate on design   | [In progress](#feedback) |
| 4. Origin trial                          | Not started              |
| 5. Launch                                | Not started              |

</div>

## How to use insertable streams for `MediaStreamTrack`

### Enabling via chrome://flags

To experiment with insertable streams for `MediaStreamTrack` locally, without an origin trial token,
enable the `#enable-experimental-web-platform-features` flag in `chrome://flags`.

### Feature detection

You can feature-detect insertable streams for `MediaStreamTrack` support as follows.

```js
if ('MediaStreamTrackProcessor' in window && 'MediaStreamTrackGenerator' in window) {
  // Insertable streams for `MediaStreamTrack` is supported.
}
```

### Core concepts

Insertable streams for `MediaStreamTrack` objects conceptually splits the `MediaStreamTrack` into
two components:

- The `TrackProcessor`, which consumes a `MediaStreamTrack` object's source and generates a stream
  of media frames ([`VideoFrame`](https://w3c.github.io/webcodecs/#videoframe-interface) or
  [`AudioFrame`](https://w3c.github.io/webcodecs/#audioframe-interface)). You can think of this as a
  track sink that is capable of exposing the unencoded frames from the track to a `ReadableStream`
  and that exposes a control channel for signals going in the opposite direction.
- The `TrackGenerator`, which consumes a stream of media frames and exposes a `MediaStreamTrack`
  interface, so that it can be used anywhere a `MediaStreamTrack` is currently attached. It takes
  video frames as input, and emits control signals that result from subsequent processing.

#### The `MediaStreamTrackProcessor`

A `MediaStreamTrackProcessor` object exposes two properties:

- `readable`: Allows reading the frames flowing through the `MediaStreamTrack`. If the track is a
  video track, chunks read from `readable` will be `VideoFrame` objects. If the track is an audio
  track, chunks read from `readable` will produce `AudioFrame` objects.
- `writableControl`: Allows sending control signals to the track. Control signals are objects of
  type `MediaStreamTrackSignal`.

#### The `MediaStreamTrackGenerator`

A `MediaStreamTrackGenerator` object likewise exposes two properties:

- `writable`: A `WritableStream` that allows writing media frames to the
  `MediaStreamTrackGenerator`, which is itself a `MediaStreamTrack`. If the `kind` attribute is
  `"audio"`, the stream will accept `AudioFrame` objects and fail with any other type. If kind is
  `"video"`, the stream will accept `VideoFrame` objects and fail with any other type. When a frame
  is written to `writable`, the frame's `close()` method is automatically invoked, so that its
  internal resources are no longer accessible from JavaScript.
- `readableControl`: A `ReadableStream` that allows reading control signals sent from any sinks
  connected to the `MediaStreamTrackGenerator`. Control signals are objects of type
  `MediaStreamTrackSignal`.

In the `MediaStream` model, apart from media, which flows from sources to sinks, there are also
control signals that flow in the opposite direction (i.e., from sinks to sources via the track). A
`MediaStreamTrackProcessor` is a sink and it allows sending control signals to its track and source
via its `writableControl` field. A `MediaStreamTrackGenerator` is a track for which a custom source
can be implemented by writing media frames to its `writable` field. Such a source can receive
control signals sent by sinks via its `readableControl` field.

### Bringing it all together

The core idea is to create a processing chain as follows:

```bash
Platform Track → Processor → Transform → Generator → Platform Sinks
```

For a barcode scanner application, this chain would look as in the code sample below.

```js
const stream = await getUserMedia({ video: true });
const videoTrack = stream.getVideoTracks()[0];

const trackProcessor = new TrackProcessor(videoTrack);
const trackGenerator = new TrackGenerator();

const transformer = new TransformStream({
  async transform(videoFrame, controller) {
    const barcodes = detectBarcodes(videoFrame);
    const newFrame = highlightBarcodes(videoFrame.data, barcodes);
    videoFrame.close();
    controller.enqueue(newFrame);
  },
});

trackProcessor.readable.pipeThrough(transformer).pipeTo(trackGenerator.writable);

trackGenerator.readableControl.pipeTo(trackProcessor.writableControl);
```

{% Aside %} This article barely scratches the surface of what is possible and going into the details
is way beyond the scope of this publication. For more examples, I refer you to the advanced
[video processing demo](https://webrtc.github.io/samples/src/content/insertable-streams/video-processing/)
and the advanced
[audio processing demo](https://webrtc.github.io/samples/src/content/insertable-streams/audio-processing/)
respectively. You can find the source code for both demos
[on GitHub](https://github.com/webrtc/samples/tree/gh-pages/src/content/insertable-streams).
{% endAside %}

## Demo

You can see the [QR code scanner demo](https://mediastreamtrack.glitch.me/) from the section above
in action on a desktop or mobile browser. Hold a QR code in front of the camera and the app will
detect it and highlight it. You can see the application's source code
[on Glitch](https://glitch.com/edit/#!/mediastreamtrack?path=index.html%3A21%3A50).

{% Img src="image/8WbTDNrhLsU0El80frMBGE4eMCD3/VwysZHgnzswePs684xOJ.png", alt="QR code scanner running in desktop browser tab showing a detected and highlighted QR code on the phone the user holds in front of the laptop's camera.", width="800", height="481" %}

## Security and Privacy considerations

The security of this API relies on existing mechanisms in the web platform. As data is exposed using
the `VideoFrame` and `AudioFrame` interfaces, the rules of those interfaces to deal with
origin-tainted data apply. For example, data from cross-origin resources cannot be accessed due to
existing restrictions to access such resources (e.g., it is not possible to access the pixels of a
cross-origin image or video element). In addition to this, access to media data from cameras,
microphones, or the screen is subject to user authorization. The media data this API exposes is
already available through other APIs. In addition to the media data, this API exposes some control
signals such as requests for new frames. These signals are intended as hints and do not pose a
significant security risk.

## Feedback

The Chromium team wants to hear about your experiences with insertable streams for
`MediaStreamTrack`.

### Tell us about the API design

Is there something about the API that does not work like you expected? Or are there missing methods
or properties that you need to implement your idea? Have a question or comment on the security
model? File a spec issue on the corresponding [GitHub repo][github], or add your thoughts to an
existing issue.

### Report a problem with the implementation

Did you find a bug with Chromium's implementation? Or is the implementation different from the spec?
File a bug at [new.crbug.com](https://new.crbug.com). Be sure to include as much detail as you can,
simple instructions for reproducing, and enter `Blink>MediaStream` in the **Components** box.
[Glitch](https://glitch.com/) works great for sharing quick and easy repros.

### Show support for the API

Are you planning to use insertable streams for `MediaStreamTrack`? Your public support helps the
Chromium team prioritize features and shows other browser vendors how critical it is to support
them.

Send a tweet to [@ChromiumDev][cr-dev-twitter] using the hashtag
[`#InsertableStreams`](https://twitter.com/search?q=%23InsertableStreams&src=recent_search_click&f=live)
and let us know where and how you are using it.

## Helpful links

- [Spec draft][spec]
- [Explainer][explainer]
- [ChromeStatus](https://chromestatus.com/features/5499415634640896)
- [Chromium bug](https://crbug.com/1142955)
- [TAG review](https://github.com/w3ctag/design-reviews/issues/603)
- [GitHub repo][github]

## Acknowledgements

The insertable streams for `MediaStreamTrack` spec was written by
[Harald Alvestrand](mailto:hta@google.com) and [Guido Urdaneta](mailto:guidou@google.com). This
article was reviewed by [Joe Medley](https://github/com/jpmedley). Hero image by
[Chris Montgomery](https://unsplash.com/@cwmonty) on
[Unsplash](https://unsplash.com/photos/smgTvepind4).

[spec]: https://w3c.github.io/mediacapture-transform/
[explainer]: https://github.com/w3c/mediacapture-transform/blob/main/explainer.md
[github]: https://github.com/w3c/mediacapture-transform/
[cr-dev-twitter]: https://twitter.com/ChromiumDev
